{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUMiNVPI5n-y"
   },
   "source": [
    "## ArgenProp Scrapping\n",
    "\n",
    "**Objetivo:** extraer información de departamentos en alquiler en Capital Federal de la página de [ArgenProp](https://www.argenprop.com/) para su posterior carga a Redshift y análisis.\n",
    "\n",
    "* El script sólo busca departamentos ordenados por más recientemente publicados. Como pasos adicionales, puede editarse la URL para extraer casas, PH, etc.\n",
    "* También podrán extraerse propiedades en venta. Esto ya se tuvo en cuenta en la estructura al agregar una variable \"sell_or_rent_ind\" para identificar si se trata de un anuncio de alquiler o de venta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\acer\\anaconda3\\lib\\site-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: redshift_connector in c:\\users\\acer\\anaconda3\\lib\\site-packages (2.0.914)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.7.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from redshift_connector) (4.11.1)\n",
      "Requirement already satisfied: lxml>=4.6.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from redshift_connector) (4.9.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from redshift_connector) (2022.7)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from redshift_connector) (2.28.1)\n",
      "Requirement already satisfied: boto3<2.0.0,>=1.9.201 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from redshift_connector) (1.26.139)\n",
      "Requirement already satisfied: botocore<2.0.0,>=1.12.201 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from redshift_connector) (1.29.139)\n",
      "Requirement already satisfied: packaging in c:\\users\\acer\\anaconda3\\lib\\site-packages (from redshift_connector) (22.0)\n",
      "Requirement already satisfied: scramp<1.5.0,>=1.2.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from redshift_connector) (1.4.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\acer\\anaconda3\\lib\\site-packages (from redshift_connector) (65.6.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from beautifulsoup4<5.0.0,>=4.7.0->redshift_connector) (2.3.2.post1)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.9.201->redshift_connector) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from boto3<2.0.0,>=1.9.201->redshift_connector) (0.6.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from botocore<2.0.0,>=1.12.201->redshift_connector) (1.26.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from botocore<2.0.0,>=1.12.201->redshift_connector) (2.8.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->redshift_connector) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->redshift_connector) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.23.0->redshift_connector) (3.4)\n",
      "Requirement already satisfied: asn1crypto>=1.5.1 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from scramp<1.5.0,>=1.2.0->redshift_connector) (1.5.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<2.0.0,>=1.12.201->redshift_connector) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install redshift_connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pytz\n",
    "import time\n",
    "import redshift_connector\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "from dotenv import dotenv_values\n",
    "from sqlalchemy import create_engine, insert, MetaData, Table\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argenprop Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "5HtGw3K7i-Jh"
   },
   "outputs": [],
   "source": [
    "utc_timezone = pytz.utc\n",
    "process_dt_utc = datetime.now(utc_timezone)\n",
    "process_dttm = process_dt_utc.strftime(\"%Y-%m-%d %H:%M:%S %Z\")\n",
    "process_dt = process_dt_utc.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "ap_base_url = 'https://www.argenprop.com'\n",
    "\n",
    "ap_new_url = ap_base_url + '/departamento-alquiler-localidad-capital-federal-orden-masnuevos-pagina-'\n",
    "\n",
    "def ap_request(url):\n",
    "  response = requests.get(url)\n",
    "\n",
    "  if response.status_code == 200:\n",
    "      # Parse HTML content using lxml\n",
    "      soup = BeautifulSoup(response.text, 'lxml')\n",
    "  else:\n",
    "      print(\"Error al obtener la página:\", response.status_code)\n",
    "\n",
    "  return soup\n",
    "\n",
    "listing_urls = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j889HkdQAwDm"
   },
   "outputs": [],
   "source": [
    "# Get the URLs of the most recent listings (First 50 pages. The website does not provide the publication date of the item.)\n",
    "# The code should be executed every day so it would not be necessary to search all the pages every day, just until we detect a property already scanned the day before\n",
    "\n",
    "for i in range(1,10):\n",
    "\n",
    "  try:\n",
    "    page_data = ap_request(ap_new_url + str(i))\n",
    "\n",
    "    listing_items_temp = page_data.find_all(class_='listing__item')\n",
    "\n",
    "    for i in listing_items_temp:\n",
    "      card_link = i.find('a', class_='card')\n",
    "\n",
    "      # Look for the listing URL inside the \"href\" atribute\n",
    "      if card_link and 'href' in card_link.attrs:\n",
    "        listing_endpoint = card_link['href']\n",
    "\n",
    "        listing_url = ap_base_url + listing_endpoint\n",
    "\n",
    "        listing_urls.append(listing_url)\n",
    "        \n",
    "  except Exception as e:\n",
    "    print('Hubo un problema al procesar la página: ' + e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listing_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.argenprop.com/departamento-en-alquiler-en-monserrat-1-ambiente--14435995',\n",
       " 'https://www.argenprop.com/departamento-en-alquiler-en-liniers-2-ambientes--14540756',\n",
       " 'https://www.argenprop.com/departamento-en-alquiler-en-villa-del-parque-3-ambientes--11763973',\n",
       " 'https://www.argenprop.com/departamento-en-alquiler-en-flores-1-ambiente--14512397',\n",
       " 'https://www.argenprop.com/departamento-en-alquiler-en-palermo-2-ambientes--14531896',\n",
       " 'https://www.argenprop.com/departamento-en-alquiler-en-almagro-2-ambientes--14541521',\n",
       " 'https://www.argenprop.com/departamento-en-alquiler-en-flores-2-ambientes--14493554',\n",
       " 'https://www.argenprop.com/departamento-en-alquiler-en-palermo-2-ambientes--14541606',\n",
       " 'https://www.argenprop.com/departamento-en-alquiler-en-belgrano-1-ambiente--14541620',\n",
       " 'https://www.argenprop.com/departamento-en-alquiler-en-las-canitas-4-ambientes--14355632']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_urls[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mZr4tf8r0iys",
    "outputId": "17bbe56b-9e86-47b0-debf-5d2680b17a98"
   },
   "outputs": [],
   "source": [
    "# Create an empty list to store property data and iterate over a list of property listing URLs\n",
    "listings_data = []\n",
    "\n",
    "for listing_url in listing_urls:\n",
    "\n",
    "  try:\n",
    "    listing_req = ap_request(listing_url)\n",
    "\n",
    "    # Some of the details of the property will always be there, but others may not be present.\n",
    "    title_address = listing_req.find(class_='titlebar__address').get_text(strip=True)\n",
    "    title_desc_short = listing_req.find(class_='titlebar__title').get_text(strip=True)\n",
    "    description_title = listing_req.find(class_='section-description--title').get_text(strip=True)\n",
    "    listing_price = listing_req.find(class_='titlebar__price').get_text(strip=True)\n",
    "\n",
    "    try:\n",
    "      listing_id = listing_url.split(\"--\")[-1]\n",
    "    except:\n",
    "      continue\n",
    "    try:\n",
    "      description_content = listing_req.find(class_='section-description--content').get_text(strip=True)\n",
    "    except:\n",
    "      description_content = None\n",
    "    try:\n",
    "      address_detail = listing_req.find(class_='location-container').find_all('p')[0].get_text(strip = True)\n",
    "    except:\n",
    "      address_detail = None\n",
    "    try:\n",
    "      address_zone = listing_req.find(class_='location-container').find_all('p')[1].get_text(strip = True)\n",
    "    except:\n",
    "      address_zone = None\n",
    "\n",
    "    # Extract all property features and keep the most relevant ones\n",
    "    features_raw = listing_req.find_all(class_='property-features')\n",
    "    features_dict = {}\n",
    "\n",
    "    for features in features_raw:\n",
    "      features_list = features.find_all('li')\n",
    "\n",
    "      for feature in features_list:\n",
    "        string = feature.get_text(strip = True)\n",
    "\n",
    "        try:\n",
    "          key, value = string.split(\":\")\n",
    "          features_dict[key.strip()] = value.strip()\n",
    "        except:\n",
    "          # If splitting by \":\" fails, assume it's a boolean feature and set it to True\n",
    "          features_dict[string] = True\n",
    "\n",
    "    listing_data_temp = {\n",
    "        'listing_id': listing_id,\n",
    "        'listing_url': listing_url,\n",
    "        'title_address': title_address,\n",
    "        'title_desc_short': title_desc_short,\n",
    "        'description_title': description_title,\n",
    "        'description_content': description_content,\n",
    "        'listing_price': listing_price,\n",
    "        'address_detail': address_detail,\n",
    "        'address_zone': address_zone,\n",
    "        'room_qty': features_dict.get('Cant. Ambientes', None),\n",
    "        'dorms_qty': features_dict.get('Cant. Dormitorios', None),\n",
    "        'baths_qty': features_dict.get('Cant. Baños', None),\n",
    "        'parking_qty': features_dict.get('Cant. Cocheras', None),\n",
    "        'property_conditions': features_dict.get('Estado', None),\n",
    "        'property_age': features_dict.get('Antiguedad', None),\n",
    "        'building_conditions': features_dict.get('Estado Edificio', None),\n",
    "        'sell_or_rent_ind': features_dict.get('Tipo de operación', None),\n",
    "        'unit_type': features_dict.get('Tipo de Unidad', None),\n",
    "        'area_built': features_dict.get('Sup. Cubierta', None),\n",
    "        'area_not_built': features_dict.get('Sup. Descubierta', None),\n",
    "        'expenses_amt': features_dict.get('Expensas', None),\n",
    "        'price_amt': features_dict.get('Precio', None),\n",
    "        'elevator_ind': features_dict.get('Ascensor', False),\n",
    "        'pets_ind': features_dict.get('Permite Mascotas', False),\n",
    "        'gym_ind': features_dict.get('Gimnasio', False),\n",
    "        'rooftop_ind': features_dict.get('Terraza', False),\n",
    "        'pool_ind': features_dict.get('Pileta', False),\n",
    "        'grill_ind': features_dict.get('Parrilla', False),\n",
    "        'solarium_ind':  features_dict.get('Solarium', False),\n",
    "        'process_dt': process_dt,\n",
    "        'process_dttm': process_dttm\n",
    "    }\n",
    "\n",
    "    listings_data.append(listing_data_temp)\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Error while processing {listing_url}\")\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "6LsgaBkAWPCk"
   },
   "outputs": [],
   "source": [
    "# Edit the format of some fields\n",
    "\n",
    "for listing in listings_data:\n",
    "    \n",
    "  # Limit description_content to 5000 characters\n",
    "  listing['description_content'] = listing['description_content'][:5000] if listing['description_content'] is not None else None\n",
    "\n",
    "  # Convert strings to int\n",
    "  int_variables = ['room_qty', 'dorms_qty', 'baths_qty', 'parking_qty', 'property_age']\n",
    "    \n",
    "  for i in int_variables:\n",
    "    listing[i] = int(listing[i]) if listing[i] is not None else None\n",
    "\n",
    "  # Convert areas to int\n",
    "  for area in ['area_built','area_not_built']:\n",
    "    area_units_str = area + '_units'\n",
    "\n",
    "    if listing[area] is None:\n",
    "      listing[area] = None\n",
    "      listing[area_units_str] = None\n",
    "\n",
    "    else:\n",
    "      try:\n",
    "        area_temp = re.match(r'([\\d,.]+)\\s*(\\S+)', listing[area])\n",
    "\n",
    "        if area_temp:\n",
    "          numeric_value_str, unit_of_measure = area_temp.groups()\n",
    "          numeric_value = int(float(numeric_value_str.replace('.', '').replace(',', '.')))\n",
    "\n",
    "          listing[area] = numeric_value\n",
    "          listing[area_units_str] = unit_of_measure\n",
    "\n",
    "        else:\n",
    "          # No data in 'area_built'\n",
    "          listing[area] = None\n",
    "          listing[area_units_str] = None\n",
    "      except:\n",
    "        print(f'Error getting the area: {area}')\n",
    "        print(listing)\n",
    "        print('')\n",
    "        break\n",
    "\n",
    "  # Edit Price (if informed)\n",
    "  if listing['price_amt'] is None or listing['listing_price'] == 'Consultar precio':\n",
    "    listing['informs_price_ind'] = False\n",
    "    listing['price_amt_units'] = None\n",
    "\n",
    "  else:\n",
    "    try:\n",
    "      price_temp = re.match(r'([^\\d]+)(\\d+(?:[,.]\\d+)?)', listing['price_amt'])\n",
    "    except:\n",
    "      print('Error getting the price')\n",
    "      print(listing)\n",
    "      print('')\n",
    "\n",
    "    if price_temp:\n",
    "      price_units, price_amt_str = price_temp.groups()\n",
    "      price_amt = int(re.sub(r'[,.]', '', price_amt_str))\n",
    "      price_units = price_units.strip().replace('$','ARS')\n",
    "\n",
    "      listing['informs_price_ind'] = True\n",
    "      listing['price_amt'] = price_amt\n",
    "      listing['price_amt_units'] = price_units\n",
    "\n",
    "    else:\n",
    "      listing['informs_price_ind'] = False\n",
    "      listing['price_amt'] = None\n",
    "      listing['price_amt_units'] = None\n",
    "\n",
    "  # Something similar for expenses (if informed)\n",
    "  if listing['expenses_amt'] is None:\n",
    "    listing['expenses_ind'] = False\n",
    "    listing['expenses_amt_units'] = None\n",
    "\n",
    "  else:\n",
    "    try:\n",
    "      expenses_temp = re.match(r'([^\\d]+)(\\d+(?:[,.]\\d+)?)', listing['expenses_amt'])\n",
    "    except:\n",
    "      print('Error getting the expenses')\n",
    "      print(listing)\n",
    "      print('')\n",
    "\n",
    "    if expenses_temp:\n",
    "      expenses_units, expenses_amt_str = expenses_temp.groups()\n",
    "      expenses_amt = int(re.sub(r'[,.]', '', expenses_amt_str))\n",
    "      expenses_units = expenses_units.strip().replace('$','ARS')\n",
    "\n",
    "      listing['expenses_ind'] = True\n",
    "      listing['expenses_amt'] = expenses_amt\n",
    "      listing['expenses_amt_units'] = expenses_units\n",
    "\n",
    "    else:\n",
    "      listing['expenses_ind'] = False\n",
    "      listing['expenses_amt'] = None\n",
    "      listing['expenses_amt_units'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8eK2kT7RsrmY",
    "outputId": "e6f1cdaa-dd9b-49bd-8c6e-d514f93ffce2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'listing_id': '14435995',\n",
       " 'listing_url': 'https://www.argenprop.com/departamento-en-alquiler-en-monserrat-1-ambiente--14435995',\n",
       " 'title_address': 'Av Rivadavia al 1300',\n",
       " 'title_desc_short': 'Departamento en Alquiler en Monserrat, Centro',\n",
       " 'description_title': 'Departamento - Monserrat',\n",
       " 'description_content': 'ALQUILER TEMPORARIO ALQUILADOMonoambiente al frente totalmente equipado para 2 personas. WIFI libre. Servicio de limpieza a cargo del inquilino.   Muy luminoso. Próximo a la Fundacion Favaloro y la UADE. Cerca de las Facultades de Medicina, ciencias Económicas y Framacio de la UBA Cerca de Avda de Mayo, Av 9 de Julio. Av Callao. Cerca de las Universidades. Varios medios de transporte.El alquiler incluye: Expensas, ABL, AYSA, servicios con tope, Cable y Wifi.',\n",
       " 'listing_price': '$ 190.000',\n",
       " 'address_detail': 'Av Rivadavia al 1300',\n",
       " 'address_zone': 'Centro, Capital Federal',\n",
       " 'room_qty': 1,\n",
       " 'dorms_qty': 1,\n",
       " 'baths_qty': 1,\n",
       " 'parking_qty': None,\n",
       " 'property_conditions': None,\n",
       " 'property_age': 15,\n",
       " 'building_conditions': None,\n",
       " 'sell_or_rent_ind': 'Alquiler',\n",
       " 'unit_type': None,\n",
       " 'area_built': 25,\n",
       " 'area_not_built': None,\n",
       " 'expenses_amt': None,\n",
       " 'price_amt': 190000,\n",
       " 'elevator_ind': False,\n",
       " 'pets_ind': False,\n",
       " 'gym_ind': False,\n",
       " 'rooftop_ind': False,\n",
       " 'pool_ind': False,\n",
       " 'grill_ind': False,\n",
       " 'solarium_ind': False,\n",
       " 'process_dt': '2023-09-29',\n",
       " 'process_dttm': '2023-09-29 18:45:05 UTC',\n",
       " 'area_built_units': 'm2',\n",
       " 'area_not_built_units': None,\n",
       " 'informs_price_ind': True,\n",
       " 'price_amt_units': 'ARS',\n",
       " 'expenses_ind': False,\n",
       " 'expenses_amt_units': None}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Redshift Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "host = config['REDSHIFT_HOST']\n",
    "port = config['REDSHIFT_PORT']\n",
    "database = config['REDSHIFT_DB']\n",
    "user = config['REDSHIFT_USER']\n",
    "password = config['SEDSHIFT_PASSWORD']\n",
    "schema = config['REDSHIFT_SCHEMA']\n",
    "table_name = config['REDSHIFT_TABLE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redshift_connection(host, port, db, user, pwd):\n",
    "  try:\n",
    "    print('Connecting to Redshift Cluster')\n",
    "    conn = redshift_connector.connect(\n",
    "      host = host,\n",
    "      database = db,\n",
    "      port = port,\n",
    "      user = user,\n",
    "      password = pwd\n",
    "    )\n",
    "    \n",
    "    # Construct the connection URL\n",
    "    db_url = f\"postgresql+psycopg2://{user}:{pwd}@{host}:{port}/{db}\"\n",
    "\n",
    "    # Create an SQLAlchemy engine\n",
    "    engine = create_engine(db_url)\n",
    "    \n",
    "    print('Connection Complete')\n",
    "    return conn, engine\n",
    "\n",
    "  except:\n",
    "    print('Failed to connect to Redshift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Redshift Cluster\n",
      "Connection Complete\n"
     ]
    }
   ],
   "source": [
    "conn, engine = redshift_connection(host, port, database, user, password) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create function to execute SQL Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_sql(conn, query):\n",
    "  try:\n",
    "    cursor = conn.cursor()\n",
    "    conn.autocomit = True\n",
    "    cursor.execute(query)\n",
    "    cols = [description[0] for description in cursor.description]\n",
    "    \n",
    "    df = pd.DataFrame(cursor.fetchall(), columns = cols)\n",
    "    return df\n",
    "\n",
    "  except Exception as e:\n",
    "    print(f\"Failed with error message: {e}\")\n",
    "    raise e\n",
    "    \n",
    "  finally:\n",
    "    cursor.close()\n",
    "#     conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Redshift data to look for dupplicates\n",
    "\n",
    "As we do not have a temporary identifier to know until when we have downloaded publications, and publications can appear or be deleted from Argenprop at any time, it is necessary to control that we do not add a publication that has been previously scanned. \n",
    "\n",
    "* We may have extracted the publication in a previous process, and it may already be in the Redshift table.\n",
    "* It can also happen that the owner has published the same apartment 2 different times. In this case, we are only interested in removing the duplicate if both listings have different prices (it may be that the listing has been updated with a different price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"SELECT DISTINCT listing_id FROM {schema}.{table_name}\"\n",
    "\n",
    "db_ids = exec_sql(conn, query)\n",
    "db_ids['listing_id'] = db_ids['listing_id'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(listings_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>listing_id</th>\n",
       "      <th>listing_url</th>\n",
       "      <th>title_address</th>\n",
       "      <th>title_desc_short</th>\n",
       "      <th>description_title</th>\n",
       "      <th>description_content</th>\n",
       "      <th>listing_price</th>\n",
       "      <th>address_detail</th>\n",
       "      <th>address_zone</th>\n",
       "      <th>room_qty</th>\n",
       "      <th>...</th>\n",
       "      <th>grill_ind</th>\n",
       "      <th>solarium_ind</th>\n",
       "      <th>process_dt</th>\n",
       "      <th>process_dttm</th>\n",
       "      <th>area_built_units</th>\n",
       "      <th>area_not_built_units</th>\n",
       "      <th>informs_price_ind</th>\n",
       "      <th>price_amt_units</th>\n",
       "      <th>expenses_ind</th>\n",
       "      <th>expenses_amt_units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>14449177</td>\n",
       "      <td>https://www.argenprop.com/departamento-en-alqu...</td>\n",
       "      <td>Chorroarin al 400</td>\n",
       "      <td>Departamento en Alquiler en Paternal, Capital ...</td>\n",
       "      <td>Departamento de 2 ambientes con baulera</td>\n",
       "      <td>Departamento de 2 ambientes a estrenar con bau...</td>\n",
       "      <td>$ 280.000</td>\n",
       "      <td>Chorroarin al 400</td>\n",
       "      <td>Paternal, Capital Federal</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2023-09-29</td>\n",
       "      <td>2023-09-29 18:45:05 UTC</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>ARS</td>\n",
       "      <td>True</td>\n",
       "      <td>ARS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   listing_id                                        listing_url  \\\n",
       "45   14449177  https://www.argenprop.com/departamento-en-alqu...   \n",
       "\n",
       "        title_address                                   title_desc_short  \\\n",
       "45  Chorroarin al 400  Departamento en Alquiler en Paternal, Capital ...   \n",
       "\n",
       "                          description_title  \\\n",
       "45  Departamento de 2 ambientes con baulera   \n",
       "\n",
       "                                  description_content listing_price  \\\n",
       "45  Departamento de 2 ambientes a estrenar con bau...     $ 280.000   \n",
       "\n",
       "       address_detail               address_zone  room_qty  ...  grill_ind  \\\n",
       "45  Chorroarin al 400  Paternal, Capital Federal       2.0  ...      False   \n",
       "\n",
       "    solarium_ind  process_dt             process_dttm  area_built_units  \\\n",
       "45         False  2023-09-29  2023-09-29 18:45:05 UTC              None   \n",
       "\n",
       "   area_not_built_units informs_price_ind price_amt_units  expenses_ind  \\\n",
       "45                 None              True             ARS          True   \n",
       "\n",
       "    expenses_amt_units  \n",
       "45                 ARS  \n",
       "\n",
       "[1 rows x 37 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 37)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 37)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge df with db_ids using a left join and indicator=True\n",
    "merged = pd.merge(df, db_ids, on='listing_id', how='left', indicator=True)\n",
    "\n",
    "# Filter rows where the indicator column is 'left_only'\n",
    "df_clean = merged[merged['_merge'] == 'left_only']\n",
    "\n",
    "# Drop the indicator column from df_clean\n",
    "df_clean = df_clean.drop(columns=['_merge'])\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 37)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.drop_duplicates(subset=['title_desc_short', 'title_address', 'listing_price'])\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Append new information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns in Redshift table don't have the same order as the ones in the dataframe, so I need to order them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a metadata object with the schema\n",
    "metadata = MetaData(schema=schema)\n",
    "\n",
    "# Reflect the existing table structure\n",
    "table = Table(table_name, metadata, autoload=True, autoload_with=engine)\n",
    "\n",
    "# Get the column names and their order from the table\n",
    "column_order = [col.name for col in table.columns]\n",
    "\n",
    "# Reorder the Dataframe\n",
    "df_clean = df_clean[column_order] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading iteration 1 out of 9\n",
      "Time taken for iteration 1: 5.888038158416748 seconds\n",
      "Uploading iteration 2 out of 9\n",
      "Time taken for iteration 2: 5.728838205337524 seconds\n",
      "Uploading iteration 3 out of 9\n",
      "Time taken for iteration 3: 6.331207752227783 seconds\n",
      "Uploading iteration 4 out of 9\n",
      "Time taken for iteration 4: 6.8381476402282715 seconds\n",
      "Uploading iteration 5 out of 9\n",
      "Time taken for iteration 5: 6.66698431968689 seconds\n",
      "Uploading iteration 6 out of 9\n",
      "Time taken for iteration 6: 5.738063097000122 seconds\n",
      "Uploading iteration 7 out of 9\n",
      "Time taken for iteration 7: 6.138419151306152 seconds\n",
      "Uploading iteration 8 out of 9\n",
      "Time taken for iteration 8: 5.793872117996216 seconds\n",
      "Uploading iteration 9 out of 9\n",
      "Time taken for iteration 9: 3.8809189796447754 seconds\n",
      "Processing complete. Total time: 53.01 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the chunk size\n",
    "chunk_size = 20\n",
    "\n",
    "# Calculate the total number of chunks\n",
    "total_chunks = len(df_clean) // chunk_size + 1\n",
    "\n",
    "# Iterate through the chunks\n",
    "\n",
    "update_start_time = time.time()\n",
    "\n",
    "for i in range(total_chunks):\n",
    "  start_idx = i * chunk_size\n",
    "  end_idx = (i + 1) * chunk_size\n",
    "  \n",
    "  # Slice the DataFrame to get the current chunk\n",
    "  current_subset = df_clean[start_idx:end_idx]\n",
    "  \n",
    "  print(f\"Uploading iteration {i + 1} out of {total_chunks}\")\n",
    "  \n",
    "  start_time = time.time()\n",
    "  \n",
    "  current_subset.to_sql(table_name, engine, schema=schema, index=False, if_exists='append', chunksize=100)\n",
    "  \n",
    "  end_time = time.time()\n",
    "  elapsed_time = end_time - start_time\n",
    "    \n",
    "  print(f\"Time taken for iteration {i + 1}: {elapsed_time} seconds\")\n",
    "\n",
    "\n",
    "update_end_time = time.time()\n",
    "total_elapsed_time = update_end_time - update_start_time\n",
    "\n",
    "print(f\"Processing complete. Total time: {total_elapsed_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Close Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
